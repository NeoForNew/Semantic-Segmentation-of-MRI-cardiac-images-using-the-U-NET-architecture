{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbwE-qUHp045",
        "outputId": "a5dcaafb-1dce-44c2-938a-b040e2ca8863"
      },
      "source": [
        "!pip install albumentations==0.4.6\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import cv2\n",
        "from torch import nn,optim\n",
        "import torch\n",
        "import torchvision.transforms.functional as TF\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class UNET(nn.Module):\n",
        "            def __init__(self):\n",
        "                        super().__init__()\n",
        "                        \n",
        "                        #DOWN SAMPLE LAYERS\n",
        "\n",
        "                        self.conv1_down_1 = nn.Conv2d(3,64,3,padding=1)\n",
        "                        self.bn1_down_1 = nn.BatchNorm2d(64)\n",
        "                        self.conv1_down_2 = nn.Conv2d(64,64,3,padding=1)\n",
        "                        self.bn1_down_2 = nn.BatchNorm2d(64)\n",
        "\n",
        "                        self.conv2_down_1 = nn.Conv2d(64,128,3,padding=1)\n",
        "                        self.bn2_down_1 = nn.BatchNorm2d(128)\n",
        "                        self.conv2_down_2 = nn.Conv2d(128,128,3,padding=1)\n",
        "                        self.bn2_down_2 = nn.BatchNorm2d(128)\n",
        "                        \n",
        "                        self.conv3_down_1 = nn.Conv2d(128,256,3,padding=1)\n",
        "                        self.bn3_down_1 = nn.BatchNorm2d(256)\n",
        "                        self.conv3_down_2 = nn.Conv2d(256,256,3,padding=1)\n",
        "                        self.bn3_down_2 = nn.BatchNorm2d(256)\n",
        "\n",
        "                        self.conv4_down_1 = nn.Conv2d(256,512,3,padding=1)\n",
        "                        self.bn4_down_1 = nn.BatchNorm2d(512)\n",
        "                        self.conv4_down_2 = nn.Conv2d(512,512,3,padding=1)\n",
        "                        self.bn4_down_2 = nn.BatchNorm2d(512)\n",
        "\n",
        "                        self.conv5_down_1 = nn.Conv2d(512,1024,3,padding=1)\n",
        "                        self.bn5_down_1 = nn.BatchNorm2d(1024)\n",
        "                        self.conv5_down_2 = nn.Conv2d(1024,1024,3,padding=1)\n",
        "                        self.bn5_down_2 = nn.BatchNorm2d(1024)\n",
        "\n",
        "                        self.pool = nn.MaxPool2d(2,2)\n",
        "\n",
        "                        #UP SAMPLE LAYERS\n",
        "\n",
        "                        self.up_sample_1 = nn.ConvTranspose2d(1024,512,2,2)\n",
        "                        self.conv1_up_1 = nn.Conv2d(1024,512,3,padding=1)\n",
        "                        self.bn1_up_1 = nn.BatchNorm2d(512)\n",
        "                        self.conv1_up_2 = nn.Conv2d(512,512,3,padding=1)\n",
        "                        self.bn1_up_2 = nn.BatchNorm2d(512)\n",
        "\n",
        "                        self.up_sample_2 = nn.ConvTranspose2d(512,256,2,2)\n",
        "                        self.conv2_up_1 = nn.Conv2d(512,256,3,padding=1)\n",
        "                        self.bn2_up_1 = nn.BatchNorm2d(256)\n",
        "                        self.conv2_up_2 = nn.Conv2d(256,256,3,padding=1)\n",
        "                        self.bn2_up_2 = nn.BatchNorm2d(256)\n",
        "\n",
        "                        self.up_sample_3 = nn.ConvTranspose2d(256,128,2,2)\n",
        "                        self.conv3_up_1 = nn.Conv2d(256,128,3,padding=1)\n",
        "                        self.bn3_up_1 = nn.BatchNorm2d(128)\n",
        "                        self.conv3_up_2 = nn.Conv2d(128,128,3,padding=1)\n",
        "                        self.bn3_up_2 = nn.BatchNorm2d(128)\n",
        "\n",
        "                        self.up_sample_4 = nn.ConvTranspose2d(128,64,2,2)\n",
        "                        self.conv4_up_1 = nn.Conv2d(128,64,3,padding=1)\n",
        "                        self.bn4_up_1 = nn.BatchNorm2d(64)\n",
        "                        self.conv4_up_2 = nn.Conv2d(64,64,3,padding=1)\n",
        "                        self.bn4_up_2 = nn.BatchNorm2d(64)\n",
        "\n",
        "                        self.output = nn.Conv2d(64,4,1)\n",
        "\n",
        "            def forward(self,x):\n",
        "\n",
        "                        #DOWN SAMPLING\n",
        "                        cd1 = self.conv1_down_1(x)\n",
        "                        cd1 = self.bn1_down_1(cd1)\n",
        "                        cd1 = F.relu(cd1)\n",
        "                        cd1 = self.conv1_down_2(cd1)\n",
        "                        cd1 = self.bn1_down_2(cd1)\n",
        "                        cd1 = F.relu(cd1)\n",
        "                        \n",
        "                        cd2 = self.pool(cd1)\n",
        "                        \n",
        "                        cd2 = self.conv2_down_1(cd2)\n",
        "                        cd2 = self.bn2_down_1(cd2)\n",
        "                        cd2 = F.relu(cd2)\n",
        "                        cd2 = self.conv2_down_2(cd2)\n",
        "                        cd2 = self.bn2_down_2(cd2)\n",
        "                        cd2 = F.relu(cd2)\n",
        "                        \n",
        "                        cd3 = self.pool(cd2)\n",
        "                        \n",
        "                        cd3 = self.conv3_down_1(cd3)\n",
        "                        cd3 = self.bn3_down_1(cd3)\n",
        "                        cd3 = F.relu(cd3)\n",
        "                        cd3 = self.conv3_down_2(cd3)\n",
        "                        cd3 = self.bn3_down_2(cd3)\n",
        "                        cd3 = F.relu(cd3)\n",
        "                        \n",
        "                        cd4 = self.pool(cd3)\n",
        "                        \n",
        "                        cd4 = self.conv4_down_1(cd4)\n",
        "                        cd4 = self.bn4_down_1(cd4)\n",
        "                        cd4 = F.relu(cd4)\n",
        "                        cd4 = self.conv4_down_2(cd4)\n",
        "                        cd4 = self.bn4_down_2(cd4)\n",
        "                        cd4 = F.relu(cd4)\n",
        "                        \n",
        "                        cd5 = self.pool(cd4)\n",
        "                        \n",
        "                        cd5 = self.conv5_down_1(cd5)\n",
        "                        cd5 = self.bn5_down_1(cd5)\n",
        "                        cd5 = F.relu(cd5)\n",
        "                        cd5 = self.conv5_down_2(cd5)\n",
        "                        cd5 = self.bn5_down_2(cd5)\n",
        "                        cd5 = F.relu(cd5)\n",
        "                        \n",
        "                        #UP SAMPLING\n",
        "\n",
        "                        cu = self.up_sample_1(cd5)\n",
        "                        cu = torch.cat((cd4,cu), dim=1)\n",
        "\n",
        "                        cu = self.conv1_up_1(cu)\n",
        "                        cu = self.bn1_up_1(cu)\n",
        "                        cu = F.relu(cu)\n",
        "                        cu = self.conv1_up_2(cu)\n",
        "                        cu = self.bn1_up_2(cu)\n",
        "                        cu = F.relu(cu)\n",
        "\n",
        "                        cu = self.up_sample_2(cu)\n",
        "                        cu = torch.cat((cd3,cu), dim=1)\n",
        "\n",
        "                        cu = self.conv2_up_1(cu)\n",
        "                        cu = self.bn2_up_1(cu)\n",
        "                        cu = F.relu(cu)\n",
        "                        cu = self.conv2_up_2(cu)\n",
        "                        cu = self.bn2_up_2(cu)\n",
        "                        cu = F.relu(cu)\n",
        "\n",
        "                        cu = self.up_sample_3(cu)\n",
        "                        cu = torch.cat((cd2,cu), dim=1)\n",
        "                        \n",
        "\n",
        "                        cu = self.conv3_up_1(cu)\n",
        "                        cu = self.bn3_up_1(cu)\n",
        "                        cu = F.relu(cu)\n",
        "                        cu = self.conv3_up_2(cu)\n",
        "                        cu = self.bn3_up_2(cu)\n",
        "                        cu = F.relu(cu)\n",
        "\n",
        "                        cu = self.up_sample_4(cu)\n",
        "                        cu = torch.cat((cd1,cu), dim=1)\n",
        "\n",
        "                        cu = self.conv4_up_1(cu)\n",
        "                        cu = self.bn4_up_1(cu)\n",
        "                        cu = F.relu(cu)\n",
        "                        cu = self.conv4_up_2(cu)\n",
        "                        cu = self.bn4_up_2(cu)\n",
        "                        cu = F.relu(cu)\n",
        "\n",
        "                        output = F.log_softmax(self.output(cu),dim=1)\n",
        "\n",
        "                        return output\n",
        "\n",
        "\n",
        "class Dataset(Dataset):\n",
        "            def __init__(self,image_dir,mask_dir,transform=None):\n",
        "                        self.image_dir = image_dir\n",
        "                        self.mask_dir = mask_dir\n",
        "                        self.transform = transform\n",
        "                        self.images = os.listdir(image_dir)\n",
        "                        self.masks = os.listdir(mask_dir)\n",
        "\n",
        "            def __len__(self):\n",
        "                        return len(self.images)\n",
        "\n",
        "            def __getitem__(self,index):\n",
        "                        image_path = os.path.join(self.image_dir,self.images[index])\n",
        "                        mask_path = os.path.join(self.mask_dir,self.masks[index])\n",
        "                        image = cv2.imread(image_path)\n",
        "                        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
        "                        mask = cv2.imread(mask_path,0)\n",
        "                        mask_0 = cv2.inRange(mask,0,50)\n",
        "                        mask_1 = cv2.inRange(mask,70,120)\n",
        "                        mask_2 = cv2.inRange(mask,140,200)\n",
        "                        mask_3 = cv2.inRange(mask,200,255)\n",
        "                        array=np.array([mask_0,mask_1,mask_2,mask_3])\n",
        "                        target=np.argmax(array,axis=0)\n",
        "                        \n",
        "                        if not self.transform == None:\n",
        "                                    augmentations = self.transform(image= image,mask=target)\n",
        "                                    image = augmentations[\"image\"]\n",
        "                                    masks = augmentations[\"mask\"]\n",
        "\n",
        "                        return image,masks\n",
        "\n",
        "def plotVals(\n",
        "    losses,\n",
        "    ylim=(0, 1.5),\n",
        "    f_name=\"Losses\",\n",
        "    x_label=\"Training Step\",\n",
        "    y_label=\"Training Loss\",\n",
        "):\n",
        "    x_axis = np.arange(len(losses))\n",
        "    plt.plot(x_axis, losses, label=y_label + \" Curve\")\n",
        "    plt.xlabel(x_label)\n",
        "    plt.ylabel(y_label)\n",
        "    plt.ylim(ylim)\n",
        "    plt.legend()\n",
        "    plt.title(y_label + \" Curve\")\n",
        "    plt.savefig(\"/content/drive/MyDrive/Segmentation/MRI SEG/Plots/Multi/{}/\".format(f_name) + y_label + \".png\", bbox_inches=\"tight\")\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "training_losses = []\n",
        "validation_losses = []\n",
        "accuracies = []\n",
        "\n",
        "train_transform = A.Compose([A.Resize(height=256,width=256),\n",
        "                             A.Rotate(limit=30,p=1.0,border_mode=cv2.BORDER_CONSTANT),A.HorizontalFlip(p=0.5),\n",
        "                             A.VerticalFlip(p=0.1),A.Normalize((0),(1)),\n",
        "                             ToTensorV2()])\n",
        "\n",
        "val_transform = A.Compose([A.Resize(height=256,width=256),\n",
        "                           A.Normalize((0),(1)),\n",
        "                           ToTensorV2()])\n",
        "\n",
        "trainset = Dataset(\"/content/drive/MyDrive/Segmentation/MRI SEG/MRI/Train Images\",\"/content/drive/MyDrive/Segmentation/MRI SEG/MRI/Train Masks\",transform=train_transform)\n",
        "valset = Dataset(\"/content/drive/MyDrive/Segmentation/MRI SEG/MRI/Train Images\",\"/content/drive/MyDrive/Segmentation/MRI SEG/MRI/Train Masks\",transform = val_transform)\n",
        "\n",
        "n_train = len(trainset)\n",
        "indices = list(range(n_train))\n",
        "np.random.shuffle(indices)\n",
        "split=int(np.floor(0.05*n_train))\n",
        "train_idx,val_idx = indices[split:],indices[:split]\n",
        "tsampler,vsampler = SubsetRandomSampler(train_idx),SubsetRandomSampler(val_idx)\n",
        "train_loader = DataLoader(trainset,sampler=tsampler,batch_size = 4)\n",
        "valid_loader = DataLoader(valset,sampler=vsampler,batch_size = 4)\n",
        "\n",
        "model = UNET()\n",
        "# model.load_state_dict(torch.load(\"/content/drive/MyDrive/Segmentation/MRI SEG/Model/multi_unet_2.pth\"))\n",
        "model=model.cuda()\n",
        "optimiser = optim.Adam(model.parameters(),lr=0.0001)\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "criterion = nn.NLLLoss()\n",
        "min_acc = 0\n",
        "epochs = 30\n",
        "num_correct = 0\n",
        "num_pixels = 0\n",
        "dice_score = 0\n",
        "v_loss = 0\n",
        "for batch_idx, (images, labels) in enumerate(valid_loader):\n",
        "    # move tensors to GPU if CUDA is available\n",
        "    images, labels = images.cuda(), labels.cuda()\n",
        "    # forward pass: compute predicted outputs by passing inputs to the model\n",
        "    with torch.cuda.amp.autocast():\n",
        "         output = model(images)\n",
        "         loss=criterion(output,labels)\n",
        "         output = torch.exp(output)\n",
        "         output = (torch.argmax(output,dim=1)).float()\n",
        "         v_loss += loss.cpu().item()\n",
        "    num_correct += (output == labels).sum()\n",
        "    num_pixels += torch.numel(output)\n",
        "validation_losses.append(v_loss/len(valid_loader))\n",
        "accuracy = num_correct/num_pixels*100\n",
        "accuracies.append(accuracy.cpu().item())\n",
        "print(\"\\nEPOCH:\",0,\"\\tAccuracy:\",accuracy, \"\\tValidation Loss:\",v_loss/len(valid_loader))\n",
        "\n",
        "for e in range(1,epochs+1):\n",
        "    model.train()\n",
        "    loop = tqdm(train_loader)\n",
        "    for images,labels in loop:\n",
        "        labels=labels.long()\n",
        "        images,labels=images.cuda(),labels.cuda()\n",
        "        optimiser.zero_grad()\n",
        "        with torch.cuda.amp.autocast():\n",
        "                    output=model.forward(images)\n",
        "                    loss=criterion(output,labels)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimiser)\n",
        "        scaler.update()\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "        training_losses.append(loss.cpu().item())\n",
        "    num_correct = 0\n",
        "    num_pixels = 0\n",
        "    dice_score = 0\n",
        "    model.eval()\n",
        "    v_loss = 0\n",
        "    # iterate over test data\n",
        "    for batch_idx, (images, labels) in enumerate(valid_loader):\n",
        "    # move tensors to GPU if CUDA is available\n",
        "        images, labels = images.cuda(), labels.cuda()\n",
        "        \n",
        "    # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        with torch.cuda.amp.autocast():\n",
        "            output = model(images)\n",
        "            loss=criterion(output,labels)\n",
        "            output = torch.exp(output)\n",
        "            \n",
        "            output = (torch.argmax(output,dim=1)).float()\n",
        "            v_loss += loss.cpu().item()\n",
        "\n",
        "        num_correct += (output == labels).sum()\n",
        "        num_pixels += torch.numel(output)\n",
        "    validation_losses.append(v_loss/len(valid_loader))\n",
        "    accuracy = num_correct/num_pixels*100\n",
        "    accuracies.append(accuracy.cpu().item())\n",
        "    print(\"\\nEPOCH:\",e,\"\\tAccuracy:\",accuracy, \"\\tValidation Loss:\",v_loss/len(valid_loader))\n",
        "\n",
        "    # calculate the batch loss\n",
        "    if accuracy>min_acc:\n",
        "        print(\"Saving model\")\n",
        "        min_acc=accuracy    \n",
        "        torch.save(model.state_dict(),\"/content/drive/MyDrive/Segmentation/MRI SEG/Model/multi_unet_2.pth\")\n",
        "\n",
        "plotVals(\n",
        "    losses=training_losses,\n",
        "    ylim=(0, max(training_losses)+0.5),\n",
        "    f_name=\"Training Loss\",\n",
        "    x_label=\"Training Step\",\n",
        "    y_label=\"Training Loss\",\n",
        ")\n",
        "plotVals(\n",
        "    losses=validation_losses,\n",
        "    ylim=(0, max(validation_losses)+0.5),\n",
        "    f_name=\"Validation Loss\",\n",
        "    x_label=\"Epoch\",\n",
        "    y_label=\"Validation Loss\",\n",
        ")\n",
        "plotVals(\n",
        "    losses=accuracies,\n",
        "    ylim=(0, 100),\n",
        "    f_name=\"Accuracy\",\n",
        "    x_label=\"Epoch\",\n",
        "    y_label=\"Pixel Classification Accuracy\",\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: albumentations==0.4.6 in /usr/local/lib/python3.7/dist-packages (0.4.6)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.4.1)\n",
            "Requirement already satisfied: imgaug>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (0.4.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (4.1.2.30)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (3.13)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.15.0)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.8.2)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.18.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.2.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (7.1.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.3.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2.6.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (4.2.0)\n",
            "\n",
            "EPOCH: 0 \tAccuracy: tensor(14.2893, device='cuda:0') \tValidation Loss: 1.6346693960103122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407/407 [01:04<00:00,  6.27it/s, loss=0.349]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH: 0 \tAccuracy: tensor(96.1199, device='cuda:0') \tValidation Loss: 0.323328667066314\n",
            "Saving model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407/407 [01:04<00:00,  6.28it/s, loss=0.159]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH: 0 \tAccuracy: tensor(96.9333, device='cuda:0') \tValidation Loss: 0.172585242851214\n",
            "Saving model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407/407 [01:04<00:00,  6.31it/s, loss=0.185]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH: 0 \tAccuracy: tensor(96.6444, device='cuda:0') \tValidation Loss: 0.1309696656059135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407/407 [01:04<00:00,  6.32it/s, loss=0.069]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH: 0 \tAccuracy: tensor(97.1013, device='cuda:0') \tValidation Loss: 0.09922263110903176\n",
            "Saving model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407/407 [01:04<00:00,  6.28it/s, loss=0.0934]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH: 0 \tAccuracy: tensor(97.0814, device='cuda:0') \tValidation Loss: 0.10682703588496555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407/407 [01:04<00:00,  6.31it/s, loss=0.0499]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH: 0 \tAccuracy: tensor(97.2323, device='cuda:0') \tValidation Loss: 0.08892118795351549\n",
            "Saving model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407/407 [01:06<00:00,  6.12it/s, loss=0.104]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH: 0 \tAccuracy: tensor(97.2516, device='cuda:0') \tValidation Loss: 0.08048686402087862\n",
            "Saving model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407/407 [01:04<00:00,  6.26it/s, loss=0.0433]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH: 0 \tAccuracy: tensor(97.3199, device='cuda:0') \tValidation Loss: 0.07701504518362609\n",
            "Saving model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407/407 [01:04<00:00,  6.29it/s, loss=0.0522]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH: 0 \tAccuracy: tensor(97.2903, device='cuda:0') \tValidation Loss: 0.07972988537089391\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407/407 [01:04<00:00,  6.32it/s, loss=0.0609]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH: 0 \tAccuracy: tensor(97.2614, device='cuda:0') \tValidation Loss: 0.0759578448804942\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407/407 [01:04<00:00,  6.29it/s, loss=0.0554]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH: 0 \tAccuracy: tensor(97.3764, device='cuda:0') \tValidation Loss: 0.07274805796755986\n",
            "Saving model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407/407 [01:05<00:00,  6.23it/s, loss=0.0747]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH: 0 \tAccuracy: tensor(97.0840, device='cuda:0') \tValidation Loss: 0.0836539552970366\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407/407 [01:04<00:00,  6.26it/s, loss=0.159]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH: 0 \tAccuracy: tensor(97.3748, device='cuda:0') \tValidation Loss: 0.07336770218204368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407/407 [01:05<00:00,  6.25it/s, loss=0.0364]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH: 0 \tAccuracy: tensor(97.3863, device='cuda:0') \tValidation Loss: 0.07253034345128319\n",
            "Saving model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407/407 [01:05<00:00,  6.25it/s, loss=0.0655]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH: 0 \tAccuracy: tensor(97.3778, device='cuda:0') \tValidation Loss: 0.07144215821542522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407/407 [01:05<00:00,  6.23it/s, loss=0.0775]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH: 0 \tAccuracy: tensor(97.3364, device='cuda:0') \tValidation Loss: 0.07041824879971417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407/407 [01:05<00:00,  6.21it/s, loss=0.0954]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH: 0 \tAccuracy: tensor(97.3385, device='cuda:0') \tValidation Loss: 0.09880645979534496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407/407 [01:05<00:00,  6.24it/s, loss=0.0393]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH: 0 \tAccuracy: tensor(97.3695, device='cuda:0') \tValidation Loss: 0.0727871023118496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407/407 [01:04<00:00,  6.28it/s, loss=0.0345]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH: 0 \tAccuracy: tensor(97.3560, device='cuda:0') \tValidation Loss: 0.06921309656040235\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407/407 [01:04<00:00,  6.31it/s, loss=0.0356]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH: 0 \tAccuracy: tensor(97.2319, device='cuda:0') \tValidation Loss: 0.09473963200368664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407/407 [01:04<00:00,  6.33it/s, loss=0.0678]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH: 0 \tAccuracy: tensor(97.3564, device='cuda:0') \tValidation Loss: 0.07378191924230619\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407/407 [01:04<00:00,  6.34it/s, loss=0.0349]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH: 0 \tAccuracy: tensor(97.4257, device='cuda:0') \tValidation Loss: 0.07126809555021199\n",
            "Saving model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407/407 [01:04<00:00,  6.28it/s, loss=0.055]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH: 0 \tAccuracy: tensor(97.3361, device='cuda:0') \tValidation Loss: 0.07347118380394849\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407/407 [01:04<00:00,  6.33it/s, loss=0.192]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH: 0 \tAccuracy: tensor(97.1598, device='cuda:0') \tValidation Loss: 0.07473786649378864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407/407 [01:04<00:00,  6.33it/s, loss=0.037]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH: 0 \tAccuracy: tensor(97.3668, device='cuda:0') \tValidation Loss: 0.07448158819567073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407/407 [01:04<00:00,  6.32it/s, loss=0.0341]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH: 0 \tAccuracy: tensor(97.2845, device='cuda:0') \tValidation Loss: 0.07329791394824331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407/407 [01:04<00:00,  6.35it/s, loss=0.0615]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH: 0 \tAccuracy: tensor(97.2390, device='cuda:0') \tValidation Loss: 0.074742602692409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407/407 [01:04<00:00,  6.34it/s, loss=0.08]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH: 0 \tAccuracy: tensor(97.3774, device='cuda:0') \tValidation Loss: 0.07088587365367195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407/407 [01:04<00:00,  6.36it/s, loss=0.0708]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH: 0 \tAccuracy: tensor(97.4358, device='cuda:0') \tValidation Loss: 0.07047555781900883\n",
            "Saving model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407/407 [01:04<00:00,  6.34it/s, loss=0.0302]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EPOCH: 0 \tAccuracy: tensor(97.2492, device='cuda:0') \tValidation Loss: 0.07511622086167336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woa5TO4VwNnW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d705d9e4-eb85-4dc0-c2cc-cbf3380b8b20"
      },
      "source": [
        "print(output.shape,labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 256, 256]) torch.Size([4, 1, 256, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRr7z5_FhesC"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}